{
 "metadata": {
  "name": "",
  "signature": "sha256:da330febb95e2c398290ca013447bc99afcd33a782d3a4e290ec881641a560d2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2\n",
      "import numpy as np\n",
      "import pysrt\n",
      "import os\n",
      "import datetime\n",
      "\n",
      "print cv2.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.4.9\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "VIDEO = r\"E:\\DOWNLOADS\\Happy Endings Season 1 Complete 720p\\Happy.Endings.S01E01.720p.HDTV.x264.mkv\"\n",
      "SUBTITLES = r\"E:\\DOWNLOADS\\Happy Endings Season 1 Complete 720p\\Happy.Endings.S01E01.720p.HDTV.x264.srt\"\n",
      "\n",
      "\n",
      "\n",
      "WORKSPACE = r'e:\\workspace\\movie2comics'\n",
      "\n",
      "HAAR_CASCADE_XML = os.path.join(WORKSPACE, 'haarcascade_frontalface_default.xml')\n",
      "DEFAULT_RES_VIDEO = os.path.join(WORKSPACE, 'res.MKV')\n",
      "\n",
      "\n",
      "assert all(os.path.exists(p) for p in [VIDEO, SUBTITLES, HAAR_CASCADE_XML])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def open_video(path=VIDEO):\n",
      "    video = cv2.VideoCapture()\n",
      "    video.open(path)\n",
      "    assert video.isOpened(), \"failled to open video!\"\n",
      "    return video\n",
      "\n",
      "def open_srt(path=SUBTITLES):\n",
      "    subs = pysrt.open(SUBTITLES)\n",
      "    return subs\n",
      "\n",
      "def open_video_writer(video, path=DEFAULT_RES_VIDEO, color=True, factor=0.3):\n",
      "    four_cc = cv2.cv.CV_FOURCC(*'XVID')\n",
      "    fps = int(video.get(cv2.cv.CV_CAP_PROP_FPS))\n",
      "    frame_size = int(video.get(cv2.cv.CV_CAP_PROP_FPS))\n",
      "    frame_width = int(video.get(cv2.cv.CV_CAP_PROP_FRAME_WIDTH) * factor)\n",
      "    frame_height = int(video.get(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT) * factor)\n",
      "    res_video = cv2.VideoWriter()\n",
      "    print res_video.open(path, four_cc, fps, (frame_width, frame_height), color)\n",
      "\n",
      "    assert res_video.isOpened()\n",
      "    return res_video\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# seek to the 100th subtitle\n",
      "subline = subs[140]\n",
      "\n",
      "video.set(cv2.cv.CV_CAP_PROP_POS_MSEC, subtime_to_ms(subline.start))\n",
      "\n",
      "print subline.start, subline.text\n",
      "display(video.read()) \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "00:06:35,061 Ow. Ow.\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def subtime_to_ms(sub_time):\n",
      "    MS_IN_HOUR = 3600000\n",
      "    MS_IN_MINUE = 60000\n",
      "    MS_IN_SEC = 1000\n",
      "    MS_IN_MS = 1\n",
      "    return sub_time.milliseconds + MS_IN_SEC * sub_time.seconds + MS_IN_MINUE * sub_time.minutes + MS_IN_HOUR * sub_time.hours"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def display(read_result):\n",
      "    if len(read_result) == 2:\n",
      "        assert len(read_result) == 2 and read_result[0] == True\n",
      "        imgae = read_result[1]\n",
      "    else:\n",
      "        image = read_result\n",
      "    cv2.imshow('img', image)\n",
      "    cv2.waitKey()\n",
      "    cv2.destroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_subs(subs):\n",
      "    for s in subs:\n",
      "        if s.text.startswith(\"-\"):\n",
      "            subs.remove(s)\n",
      "            for l in reversed(s.text.splitlines()):\n",
      "                l_text = l[1:].strip()\n",
      "                subs.insert(s.index, pysrt.SubRipItem(start=s.start, end=s.end, text=l_text))\n",
      "split_subs(subs)\n",
      "subs.save(r'e:\\temp\\s2.srt', encoding='utf-8')\n",
      "                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "video = open_video()\n",
      "vw = open_video_writer(video)\n",
      "try:\n",
      "    fd = FaceDetector()\n",
      "    while True:\n",
      "        img = video.read()[1]\n",
      "        vw.write(fd.process(img))\n",
      "finally:\n",
      "    video.release()\n",
      "    vw.release()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-84-60214912bd19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mvw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-83-16667ece5537>\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mminNeighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mminSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mflags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCV_HAAR_SCALE_IMAGE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         )\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#print \"Found {0} faces!\".format(len(faces))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv2.resize"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "> \u001b[1;32m<ipython-input-30-0dafce36bc24>\u001b[0m(4)\u001b[0;36m__init__\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32m      3 \u001b[1;33m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcascade_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mHAAR_CASCADE_XML\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[0m\u001b[1;32m----> 4 \u001b[1;33m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_face_cascade\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcascade_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[0m\u001b[1;32m      5 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[0m\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ipdb> cascade_path\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<__main__.FaceDetector object at 0x05736B70>\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ipdb> ec\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "*** NameError: name 'ec' is not defined\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ipdb> c\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FaceDetector(object):\n",
      "    \n",
      "    def __init__(self, cascade_path=HAAR_CASCADE_XML):\n",
      "        self._face_cascade = cv2.CascadeClassifier(cascade_path)\n",
      "        \n",
      "    def process(self, image):\n",
      "        resized_image = cv2.resize(image, (0,0), fx=0.3, fy=0.3) \n",
      "        gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "        # Detect faces in the image\n",
      "        faces = self._face_cascade.detectMultiScale(\n",
      "            gray,\n",
      "            scaleFactor=1.1,\n",
      "            minNeighbors=5,\n",
      "            minSize=(30, 30),\n",
      "            flags = cv2.cv.CV_HAAR_SCALE_IMAGE\n",
      "        )\n",
      "        #print \"Found {0} faces!\".format(len(faces))\n",
      "        \n",
      "        for (x, y, w, h) in faces:\n",
      "            cv2.rectangle(resized_image, (x, y), (x+w, y+h), (0, 255, 0), 10)\n",
      "\n",
      "        #res_image = cv2.resize(resized_image, image.shape[:2]) \n",
      "        #print res_image.shape[:2]\n",
      "        \n",
      "        #display(resized_image)\n",
      "        return resized_image\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img.shape[:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "(720, 1280)"
       ]
      }
     ],
     "prompt_number": 46
    }
   ],
   "metadata": {}
  }
 ]
}